{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "정범진 4차과제.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1Cc4GGPPAtP"
      },
      "source": [
        "#과제1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVT5_WsnPDBU"
      },
      "source": [
        "##조기 종료를 사용한 배치 경사 하강법으로 로지스틱 회귀를 구현하라. 단 사이킷런을 전혀 사용하지 않아야 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FneEhEBj_YAv"
      },
      "source": [
        "## 데이터 준비\n",
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "iris = datasets.load_iris()\n",
        "X = iris[\"data\"][:, 3:]                   # 1개의 특성(꽃잎 너비)만 사용\n",
        "y = (iris[\"target\"] == 2).astype(np.int)  # 버지니카(Virginica) 품종일 때 1(양성)\n",
        "\n",
        "X_with_bias = np.c_[np.ones([len(X), 1]), X]\n",
        "np.random.seed(2042)\n",
        "\n",
        "## 데이터 분할\n",
        "test_ratio = 0.2                                         # 테스트 세트 비율 = 20%\n",
        "validation_ratio = 0.2                                   # 검증 세트 비율 = 20%\n",
        "total_size = len(X_with_bias)                            # 전체 데이터셋 크기\n",
        "\n",
        "test_size = int(total_size * test_ratio)                 # 테스트 세트 크기: 전체의 20%\n",
        "validation_size = int(total_size * validation_ratio)     # 검증 세트 크기: 전체의 20%\n",
        "train_size = total_size - test_size - validation_size    # 훈련 세트 크기: 전체의 60%\n",
        "\n",
        "rnd_indices = np.random.permutation(total_size)\n",
        "\n",
        "X_train = X_with_bias[rnd_indices[:train_size]]\n",
        "y_train = y[rnd_indices[:train_size]]\n",
        "\n",
        "X_valid = X_with_bias[rnd_indices[train_size:-test_size]]\n",
        "y_valid = y[rnd_indices[train_size:-test_size]]\n",
        "\n",
        "X_test = X_with_bias[rnd_indices[-test_size:]]\n",
        "y_test = y[rnd_indices[-test_size:]]\n",
        "\n",
        "Y_train = np.reshape(y_train,(90,1))\n",
        "y_valid = np.reshape(y_valid,(30,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T82EGU6fPbmy"
      },
      "source": [
        "로지스틱함수 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKR7eAFUNWBv"
      },
      "source": [
        "def logistic_sigmoid(x): # 시그모이드 함수 정의\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "n_inputs = X_train.shape[1]           # 특성 수(n) + 1, 붓꽃의 경우: 특성 2개 + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ7oxlMAPdAj"
      },
      "source": [
        "조기종료 + 배치 경사 하강법 + 로지스틱 회귀"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJASf1k5NWMO",
        "outputId": "88347c05-8e8d-4d8f-f56c-d16ad5d552e9"
      },
      "source": [
        "eta = 0.1\n",
        "n_iterations = 10001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.1           # 규제 하이퍼파라미터\n",
        "best_loss = np.infty   # 최소 손실값 기억 변수\n",
        "\n",
        "Theta = np.random.randn(n_inputs, 1)  # 파라미터 새로 초기화\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    # 훈련 및 손실 계산\n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = logistic_sigmoid(logits)\n",
        "    error = Y_proba - Y_train\n",
        "    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, 1]), alpha * Theta[1:]]\n",
        "    Theta = Theta - eta * gradients\n",
        "\n",
        "    # 검증 세트에 대한 손실 계산\n",
        "    logits = X_valid.dot(Theta)\n",
        "    Y_proba = logistic_sigmoid(logits)\n",
        "    xentropy_loss2 = -1/m*(np.sum(y_valid * np.log(Y_proba + epsilon) + (1 - y_valid ) * np.log(1 - Y_proba + epsilon)))\n",
        "    l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n",
        "    loss = xentropy_loss2 + alpha * l2_loss\n",
        "\n",
        "   \n",
        "    # 500 에포크마다 검증 세트에 대한 손실 출력\n",
        "    if iteration % 500 == 0:\n",
        "        print(iteration, loss)\n",
        "        \n",
        "    # 에포크마다 최소 손실값 업데이트\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "    else:                                      # 에포크가 줄어들지 않으면 바로 훈련 종료\n",
        "        print(iteration - 1, best_loss)        # 종료되지 이전 에포크의 손실값 출력\n",
        "        print(iteration, loss, \"조기 종료!\")\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.2463555980311719\n",
            "143 0.18575075571718722\n",
            "144 0.18575156557083228 조기 종료!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6-Tj-7aIxI6",
        "outputId": "998f6a6a-6bb8-4af9-a084-9dac6d099722"
      },
      "source": [
        "logits = X_valid.dot(Theta)\n",
        "Y_proba = logistic_sigmoid(logits)\n",
        "Y_proba2 = np.where(Y_proba >= 0.5 ,1,0)\n",
        "y_predict = Y_proba2\n",
        "\n",
        "y_valid = y_valid.reshape(30, 1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid)\n",
        "accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QefTu5Wp_2e0",
        "outputId": "a073b682-59dc-41ca-941d-d17334c78515"
      },
      "source": [
        "logits = X_valid.dot(Theta)\n",
        "Y_proba = logistic_sigmoid(logits)\n",
        "Y_proba2 = np.where(Y_proba >= 0.5 ,1,0)\n",
        "y_predict = Y_proba2\n",
        "\n",
        "y_valid = y_test.reshape(30, 1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_test)\n",
        "accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5888888888888889"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo3luS8y_3VQ",
        "outputId": "d7f839dd-a03e-47b0-da23-c8853d2291df"
      },
      "source": [
        "Theta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.34559323],\n",
              "       [ 0.728139  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECh5E4fDyI3X"
      },
      "source": [
        "#과제2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBNPuTjvOj4Z"
      },
      "source": [
        "##과제 1에서 구현된 로지스틱 회귀 알고리즘에 일대다(OvR) 방식을 적용하여 붓꽃에 대한 다중 클래스 분류 알고리즘을 구현하라. 단 사이킷런을 전혀 사용하지 않아야 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt_v8q2eLpYU"
      },
      "source": [
        "## 데이터 준비\n",
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris[\"data\"][:, 3:]                   # 1개의 특성(꽃잎 너비)만 사용\n",
        "y = (iris[\"target\"]).astype(np.int)  # 버지니카(Virginica) 품종일 때 1(양성)\n",
        "\n",
        "X_with_bias = np.c_[np.ones([len(X), 1]), X]\n",
        "np.random.seed(2042)\n",
        "\n",
        "## 데이터셋 분할\n",
        "test_ratio = 0.2                                         # 테스트 세트 비율 = 20%\n",
        "validation_ratio = 0.2                                   # 검증 세트 비율 = 20%\n",
        "total_size = len(X_with_bias)                            # 전체 데이터셋 크기\n",
        "\n",
        "test_size = int(total_size * test_ratio)                 # 테스트 세트 크기: 전체의 20%\n",
        "validation_size = int(total_size * validation_ratio)     # 검증 세트 크기: 전체의 20%\n",
        "train_size = total_size - test_size - validation_size    # 훈련 세트 크기: 전체의 60%\n",
        "\n",
        "rnd_indices = np.random.permutation(total_size)\n",
        "\n",
        "X_train = X_with_bias[rnd_indices[:train_size]]\n",
        "y_train = y[rnd_indices[:train_size]]\n",
        "\n",
        "X_valid = X_with_bias[rnd_indices[train_size:-test_size]]\n",
        "y_valid = y[rnd_indices[train_size:-test_size]]\n",
        "\n",
        "X_test = X_with_bias[rnd_indices[-test_size:]]\n",
        "y_test = y[rnd_indices[-test_size:]]\n",
        "\n",
        "\n",
        "## 타깃 변환\n",
        "def to_one_hot(y):\n",
        "    n_classes = y.max() + 1                 # 클래스 수\n",
        "    m = len(y)                              # 샘플 수\n",
        "    Y_one_hot = np.zeros((m, n_classes))    # (샘플 수, 클래스 수) 0-벡터 생성\n",
        "    Y_one_hot[np.arange(m), y] = 1          # 샘플 별로 해당 클래스의 값만 1로 변경. (넘파이 인덱싱 활용)\n",
        "    return Y_one_hot\n",
        "\n",
        "Y_train_one_hot = to_one_hot(y_train)\n",
        "Y_valid_one_hot = to_one_hot(y_valid)\n",
        "Y_test_one_hot = to_one_hot(y_test)\n",
        "\n",
        "Setosa_train=Y_train_one_hot[:,0]\n",
        "Versicolor_train = Y_train_one_hot[:,1]\n",
        "Virginica_train = Y_train_one_hot[:,2]\n",
        "\n",
        "Setosa_valid = Y_valid_one_hot[:,0]\n",
        "Versicolor_valid = Y_valid_one_hot[:,1]\n",
        "Virginica_valid = Y_valid_one_hot[:,2]\n",
        "\n",
        "Setosa_test = Y_test_one_hot[:,0]\n",
        "Versicolor_test = Y_test_one_hot[:,1]\n",
        "Virginica_test = Y_test_one_hot[:,2]\n",
        "\n",
        "Setosa_train = np.reshape(Setosa_train,(90,1))\n",
        "Versicolor_train = np.reshape(Versicolor_train,(90,1))\n",
        "Virginica_train = np.reshape(Virginica_train,(90,1))\n",
        "\n",
        "Setosa_valid = np.reshape(Setosa_valid,(30,1))\n",
        "Versicolor_valid = np.reshape(Versicolor_valid,(30,1))\n",
        "Virginica_valid = np.reshape(Virginica_valid,(30,1))\n",
        "\n",
        "Y_train = np.reshape(y_train,(90,1))\n",
        "y_valid = np.reshape(y_valid,(30,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IMyGE4I2EY3"
      },
      "source": [
        "##Setosa의 최적의Theta값 구하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxL_XFAPzIbA",
        "outputId": "7bd19691-783e-46c8-fa77-f04bdc81e238"
      },
      "source": [
        "eta = 0.0008\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.005          # 규제 하이퍼파라미터\n",
        "best_loss = np.infty   # 최소 손실값 기억 변수\n",
        "\n",
        "Theta1 = np.random.randn(n_inputs, 1)  # 파라미터 새로 초기화\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    # 훈련 및 손실 계산\n",
        "    logits = X_train.dot(Theta1)\n",
        "    Y_proba = logistic_sigmoid(logits)\n",
        "    error = Y_proba - Setosa_train\n",
        "    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, 1]), alpha * Theta1[1:]]\n",
        "    Theta1 = Theta1 - eta * gradients\n",
        "\n",
        "    # 검증 세트에 대한 손실 계산\n",
        "    logits = X_valid.dot(Theta1)\n",
        "    Y_proba = logistic_sigmoid(logits)\n",
        "    xentropy_loss2 = -1/m*(np.sum(Setosa_valid * np.log(Y_proba + epsilon) + (1 - Setosa_valid ) * np.log(1 - Y_proba + epsilon)))\n",
        "    l2_loss = 1/2 * np.sum(np.square(Theta1[1:]))\n",
        "    loss = xentropy_loss2 + alpha * l2_loss\n",
        "    \n",
        "    \n",
        "    # 500 에포크마다 검증 세트에 대한 손실 출력\n",
        "    if iteration % 500 == 0:\n",
        "        print(iteration, loss)\n",
        "        \n",
        "    # 에포크마다 최소 손실값 업데이트\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "    else:                                      # 에포크가 줄어들지 않으면 바로 훈련 종료\n",
        "        print(iteration - 1, best_loss)        # 종료되지 이전 에포크의 손실값 출력\n",
        "        print(iteration, loss, \"조기 종료!\")\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.1996296961008965\n",
            "500 0.17739812210024686\n",
            "1000 0.16299034924823363\n",
            "1500 0.15304665975108023\n",
            "2000 0.14576656980282693\n",
            "2500 0.14015313089183962\n",
            "3000 0.135630668832707\n",
            "3500 0.13185268070140238\n",
            "4000 0.12860251358669347\n",
            "4500 0.1257400034208949\n",
            "5000 0.1231716577682144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ1BSvM-zJ2U",
        "outputId": "9aa93b63-007d-4da4-bc73-a0efd9fe08d5"
      },
      "source": [
        "logits = X_valid.dot(Theta1)\n",
        "Y_proba = logistic_sigmoid(logits)\n",
        "Y_proba1 = np.where(Y_proba >= 0.5 ,1,0)\n",
        "y_predict = Y_proba1\n",
        "\n",
        "Setosa_valid = Setosa_valid.reshape(30, 1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == Setosa_valid)\n",
        "accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7666666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rXTNxHZzLJr",
        "outputId": "9ff06d1c-8398-4b49-de4f-7785ad85c40a"
      },
      "source": [
        "Theta1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.1879383 ],\n",
              "       [-1.08177422]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNkhTJWu2K1I"
      },
      "source": [
        "##Versicolor의 최적의Theta값 구하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI2LH5si2a55",
        "outputId": "831fef43-bbcf-48ab-9712-d53d12fee7c6"
      },
      "source": [
        "eta = 0.0008\n",
        "n_iterations = 10001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.005        # 규제 하이퍼파라미터\n",
        "best_loss = np.infty   # 최소 손실값 기억 변수\n",
        "\n",
        "Theta2 = np.random.randn(n_inputs, 1)  # 파라미터 새로 초기화\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    # 훈련 및 손실 계산\n",
        "    logits = X_train.dot(Theta2)\n",
        "    Y_proba = logistic_sigmoid(logits)\n",
        "    error = Y_proba - Versicolor_train\n",
        "    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, 1]), alpha * Theta2[1:]]\n",
        "    Theta2 = Theta2 - eta * gradients\n",
        "\n",
        "    # 검증 세트에 대한 손실 계산\n",
        "    logits = X_valid.dot(Theta2)\n",
        "    Y_proba = logistic_sigmoid(logits)\n",
        "    xentropy_loss2 = -1/m*(np.sum(Versicolor_valid * np.log(Y_proba + epsilon) + (1 - Versicolor_valid ) * np.log(1 - Y_proba + epsilon)))\n",
        "    l2_loss = 1/2 * np.sum(np.square(Theta2[1:]))\n",
        "    loss = xentropy_loss2 + alpha * l2_loss\n",
        "    \n",
        "    # 500 에포크마다 검증 세트에 대한 손실 출력\n",
        "    if iteration % 500 == 0:\n",
        "        print(iteration, loss)\n",
        "        \n",
        "    # 에포크마다 최소 손실값 업데이트\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "    else:                                      # 에포크가 줄어들지 않으면 바로 훈련 종료\n",
        "        print(iteration - 1, best_loss)        # 종료되지 이전 에포크의 손실값 출력\n",
        "        print(iteration, loss, \"조기 종료!\")\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.2501474525276718\n",
            "500 0.2354633253410091\n",
            "1000 0.22737208988730617\n",
            "1500 0.2230404286972585\n",
            "2000 0.220775948521791\n",
            "2500 0.21962683007372982\n",
            "3000 0.21907136046660802\n",
            "3500 0.2188265423228695\n",
            "4000 0.21873979067563534\n",
            "4344 0.2187276387887131\n",
            "4345 0.2187276388602661 조기 종료!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ix0ua-22bC8",
        "outputId": "397660d9-87a3-4b39-d0c8-14d2fa57ce9a"
      },
      "source": [
        "logits = X_valid.dot(Theta2)\n",
        "Y_proba = logistic_sigmoid(logits)\n",
        "Y_proba2 = np.where(Y_proba >= 0.5 ,1,0)\n",
        "y_predict = Y_proba2\n",
        "\n",
        "Versicolor_valid = Versicolor_valid.reshape(30, 1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == Versicolor_valid)\n",
        "accuracy_score\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brwmHCwW2cg0",
        "outputId": "14fc8c06-b61a-4c0e-fbee-b4de2dd4bc55"
      },
      "source": [
        "Theta2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.6019138 ],\n",
              "       [ 0.05651226]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVk7DO2l2TMd"
      },
      "source": [
        "##Virginica의 최적의Theta값 구하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNVrPhrw2dYJ",
        "outputId": "6890d280-fad8-4888-e0c0-84e42dde4232"
      },
      "source": [
        "eta = 0.008\n",
        "n_iterations = 10001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.005           # 규제 하이퍼파라미터\n",
        "best_loss = np.infty   # 최소 손실값 기억 변수\n",
        "\n",
        "Theta3 = np.random.randn(n_inputs, 1)  # 파라미터 새로 초기화\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    # 훈련 및 손실 계산\n",
        "    logits = X_train.dot(Theta3)\n",
        "    Y_proba = logistic_sigmoid(logits)\n",
        "    error = Y_proba - Virginica_train\n",
        "    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, 1]), alpha * Theta3[1:]]\n",
        "    Theta3 = Theta3 - eta * gradients\n",
        "\n",
        "    # 검증 세트에 대한 손실 계산\n",
        "    logits = X_valid.dot(Theta3)\n",
        "    Y_proba = logistic_sigmoid(logits)\n",
        "    xentropy_loss2 = -1/m*(np.sum(Virginica_valid * np.log(Y_proba + epsilon) + (1 - Virginica_valid ) * np.log(1 - Y_proba + epsilon)))\n",
        "    l2_loss = 1/2 * np.sum(np.square(Theta3[1:]))\n",
        "    loss = xentropy_loss2 + alpha * l2_loss\n",
        "    \n",
        "    # 500 에포크마다 검증 세트에 대한 손실 출력\n",
        "    if iteration % 500 == 0:\n",
        "        print(iteration, loss)\n",
        "        \n",
        "    # 에포크마다 최소 손실값 업데이트\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "    else:                                      # 에포크가 줄어들지 않으면 바로 훈련 종료\n",
        "        print(iteration - 1, best_loss)        # 종료되지 이전 에포크의 손실값 출력\n",
        "        print(iteration, loss, \"조기 종료!\")\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.3071496303877346\n",
            "500 0.19003757265572152\n",
            "1000 0.16832111271168623\n",
            "1500 0.15358816175031445\n",
            "2000 0.1429649320569367\n",
            "2500 0.13503119590818174\n",
            "3000 0.1289289598008823\n",
            "3500 0.12411975432260966\n",
            "4000 0.12025301909929337\n",
            "4500 0.11709255918482002\n",
            "5000 0.1144742113381786\n",
            "5500 0.11228067128753232\n",
            "6000 0.11042603494315612\n",
            "6500 0.10884601110333854\n",
            "7000 0.1074915478759696\n",
            "7500 0.10632457395054987\n",
            "8000 0.10531508562125125\n",
            "8500 0.10443911153183927\n",
            "9000 0.10367726296976444\n",
            "9500 0.10301368295886074\n",
            "10000 0.10243527215439507\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGan9EzM2dSE",
        "outputId": "6c9c0db3-1856-4010-86d6-7429f32f5115"
      },
      "source": [
        "logits = X_valid.dot(Theta3)\n",
        "Y_proba = logistic_sigmoid(logits)\n",
        "Y_proba3 = np.where(Y_proba >= 0.5 ,1,0)\n",
        "y_predict = Y_proba3\n",
        "\n",
        "Virginica_valid = Virginica_valid.reshape(30, 1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == Virginica_valid)\n",
        "accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACWd2Ify2dIa",
        "outputId": "29a3afc0-b3ef-41be-fe04-a42c7b6f7a7f"
      },
      "source": [
        "Theta3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-4.20758763],\n",
              "       [ 2.563671  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oarig76NfXv"
      },
      "source": [
        "### 각각의 최적의Theta값을 Y_proba에 배열시킨 후 가장 높은 확률을 갖는 클래스를 선택함."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n9DIvKUGbc0",
        "outputId": "e807c34f-a1e3-4950-d980-ce2c021d004b"
      },
      "source": [
        "## 검증세트\n",
        "\n",
        "logits_Setosa = X_valid.dot(Theta1)\n",
        "logits_Versicolor = X_valid.dot(Theta2)\n",
        "logits_Virginica = X_valid.dot(Theta3)\n",
        "\n",
        "Y_proba_Setosa = logistic_sigmoid(logits_Setosa)\n",
        "Y_proba_Versicolor = logistic_sigmoid(logits_Versicolor)\n",
        "Y_proba_Virginica = logistic_sigmoid(logits_Virginica)\n",
        "\n",
        "Y_proba = np.hstack((Y_proba_Setosa,Y_proba_Versicolor,Y_proba_Virginica))\n",
        "y_predict = np.argmax(Y_proba, axis=1)          # 가장 높은 확률을 갖는 클래스 선택\n",
        "\n",
        "y_predict = np.reshape(y_predict,(30,1))\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid)  # 정확도 계산\n",
        "accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMOCMyRj4sBv",
        "outputId": "8c0ea52a-c420-4a67-c3df-81cdf6f3bd91"
      },
      "source": [
        "##테스트 세트\n",
        "\n",
        "logits_Setosa = X_test.dot(Theta1)\n",
        "logits_Versicolor = X_test.dot(Theta2)\n",
        "logits_Virginica = X_test.dot(Theta3)\n",
        "\n",
        "Y_proba_Setosa = logistic_sigmoid(logits_Setosa)\n",
        "Y_proba_Versicolor = logistic_sigmoid(logits_Versicolor)\n",
        "Y_proba_Virginica = logistic_sigmoid(logits_Virginica)\n",
        "\n",
        "Y_proba = np.hstack((Y_proba_Setosa, Y_proba_Versicolor, Y_proba_Virginica))\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_test)\n",
        "accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDigV_JMSDPS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
